# final_test_and_export_v19.py

import re
import unicodedata
import time
import pprint
import csv
from document_processor import pdf_to_text
from reference_extractor import REF_RE

# -------------------- V19 æ ¸å¿ƒå‡½å¼ --------------------
def extract_citations_v19(text: str):
    # --- æ­¥é©Ÿ 1: å¼·åŠ›é è™•ç† ---
    text = unicodedata.normalize("NFC", text).replace("â€™", "'")
    text = re.sub(r'[\x00-\x1f\u200b\ufeff]', '', text)

    # text = unicodedata.normalize("NFKD", text)
    # text = ''.join(ch for ch in text if not unicodedata.combining(ch))

    results = []
    processed_mask = [False] * len(text)
    YEAR_PAT = r"\b\d{4}[a-z]?\b"

    # --- æ­¥é©Ÿ 2: å®šç¾©å…©å¥—ç¨ç«‹ä¸”ç¶“éå¼·åŒ–çš„è¦å‰‡ ---
    
    # è¦å‰‡ A: å°ˆé–€è™•ç†è‹±æ–‡/è¥¿æ–‡å¼•ç”¨ï¼Œä¸¦é–‹æ”¾ã€Œç™½åå–®ã€ä¸­æ–‡é€£æ¥è©
    # é€™æ˜¯é€™æ¬¡ä¿®æ”¹çš„éˆé­‚ï¼šåœ¨å…è¨±çš„å­—å…ƒé›†ä¸­ï¼ŒåŠ å…¥äº† èˆ‡, å’Œ, ä»¥åŠ
    ENG_AUTHOR_CHARS_WITH_WHITELIST = r"[A-Za-zÃ€-Å¾\d&'.,\-\sèˆ‡å’Œä»¥åŠ]"
    
    ENG_CITE_PAT = re.compile(
        rf"""
        # ç¢ºä¿å·¦é‚Šç•Œä¸æ˜¯ä¸€å€‹ç·Šè·Ÿè‘—çš„ä¸­æ–‡å­—ï¼Œé¿å…å¾ä¸­æ–‡å¥å­ä¸­é–“é–‹å§‹åŒ¹é…
        (?<![A-Za-z]) 
        (?P<author>{ENG_AUTHOR_CHARS_WITH_WHITELIST}{{1,79}}?) # éè²ªå©ªåŒ¹é…ï¼Œé™åˆ¶é•·åº¦
        (?:\s*(?:et\s+al\.|ç­‰[\s\u3000]*äºº?)\s*)?
        \s*
        [ï¼ˆ(]
        \s*
        (?P<year>{YEAR_PAT})
        .*?
        [)ï¼‰]
        """,
        re.I | re.VERBOSE
    )

    # è¦å‰‡ B: å°ˆé–€è™•ç†ä¸­æ–‡å¼•ç”¨ï¼Œä¸¦ä¿®æ­£äº† "ç­‰ äºº" çš„å•é¡Œ
    CHI_AUTHOR_CHARS = r"[ä¸€-é¾¥]"
    CHI_CITE_PAT = re.compile(
        rf"""
        (?P<author>{CHI_AUTHOR_CHARS}+(?:\s*ç­‰\s*äºº?)?) # å…è¨± "ç­‰" å’Œ "äºº" ä¹‹é–“æœ‰ç©ºæ ¼
        \s*
        [ï¼ˆ(]
        \s*
        (?P<year>{YEAR_PAT})
        .*?
        [)ï¼‰]
        """,
        re.I | re.VERBOSE
    )

    # --- æ­¥é©Ÿ 3: åˆ†åˆ¥åŸ·è¡Œï¼Œå…ˆè‹±æ–‡å¾Œä¸­æ–‡ ---
    
    # åŸ·è¡Œè‹±æ–‡å¼•ç”¨æ“·å–


    for m in ENG_CITE_PAT.finditer(text):
        start, end = m.span()
        if any(processed_mask[start:end]): continue
        
        author_candidate = m.group('author').strip()
        # author_match = re.search(r"([A-Za-z].*)$", author_candidate) # ç¢ºä¿ä»¥è‹±æ–‡å­—æ¯é–‹é ­
        # if not author_match: continue
        
        # author_str = author_match.group(1).strip(" ,ã€ï¼Œ")
        author_str = re.sub(r'^[^A-Za-z]+', '', author_candidate).strip(" ,ã€ï¼Œ")
        
        # å¥å…¨æ€§æª¢æŸ¥
        if len(author_str) < 2 or len(author_str.split()) > 8:
            continue

        results.append({ "raw_text": m.group(0).strip(), "author": author_str, "year": m.group('year')})
        processed_mask[start:end] = [True] * (end - start)

    # åŸ·è¡Œä¸­æ–‡å¼•ç”¨æ“·å–
    for m in CHI_CITE_PAT.finditer(text):
        start, end = m.span()
        if any(processed_mask[start:end]): continue
        
        author_str = m.group('author').strip()
        results.append({ "raw_text": m.group(0).strip(), "author": author_str, "year": m.group('year')})
        processed_mask[start:end] = [True] * (end - start)

    # --- æ­¥é©Ÿ 4: è™•ç†æ‹¬è™Ÿå…§çš„å¼•ç”¨ ---
    paren_pat = re.compile(r"\(([^()]+?)\)")
    separator = re.compile(r"[;ï¼›]")
    for m in paren_pat.finditer(text):
        start, end = m.span()
        if any(processed_mask[start:end]): continue
        content = m.group(1)
        if ',' not in content: continue
        
        parts = separator.split(content)
        temp_results = []
        is_valid = True
        for part in parts:
            match = re.fullmatch(rf"^(?P<author>.+?),\s*(?P<year>{YEAR_PAT})(?:\s*[,;ï¼Œï¼›].+)?$", part.strip(), re.I)
            if match:
                temp_results.append({"raw_text": f"({part.strip()})", "author": match.group('author').strip(), "year": match.group('year')})
            else:
                is_valid = False; break
        if is_valid:
            results.extend(temp_results)

    # --- æ­¥é©Ÿ 5: æœ€çµ‚å»é‡èˆ‡æ¨™æº–åŒ– ---
    unique_results = []
    seen_keys = set()
    seen_raw = set()

    for res in results:
        # æ¨™æº–åŒ–ï¼šå°‡ä¸­æ–‡é€£æ¥è©æ›æˆ &
        author_std = res['author'].replace(" èˆ‡ ", " & ").replace(" å’Œ ", " & ").replace(" ä»¥åŠ ", " & ")

        backup = author_std 
        # å¼·åŠ›æ¸…ç†ä½œè€…çµå°¾çš„ "et al." å’Œ "ç­‰"
        author_clean = re.sub(r'\s*(et\s+al\.|ç­‰(?:äºº)?)$', '', author_std, flags=re.I).strip()
        
        if not author_clean:          # â† æ–°å¢ï¼šå‰ªæ‰å¾Œè®Šç©ºå°±é‚„åŸ
            author_clean = backup.strip()

        author_clean = re.sub(r'^(?:ä»¥åŠ|å’Œ|èˆ‡|åŠ)\s*', '', author_clean, flags=re.I)
        author_clean = re.sub(r'\d+', '', author_clean)   # åˆªæ‰æ‰€æœ‰ 0-9
        author_clean = re.sub(r'\s{2,}', ' ', author_clean).strip()  # åˆä½µå¤šé¤˜ç©ºç™½

        if res['raw_text'] in seen_raw:
            continue
        seen_raw.add(res['raw_text'])

        if not author_clean:
            continue       

        if re.search(r'\d', author_clean):
            continue

        if re.fullmatch(r"[A-Za-z]\.?", author_clean):
            continue

        if re.fullmatch(r"(?:al\.?|ç­‰äºº?)$", author_clean, re.I):
            continue

        
        
        key = (author_clean.lower(), res['year'])
        if key not in seen_keys:
            seen_keys.add(key)
            res['author'] = author_clean
            unique_results.append(res)
            
    return sorted(unique_results, key=lambda x: (x['author'].lower(), x['year']))

# --- ä¸»æ¸¬è©¦èˆ‡åŒ¯å‡ºé‚è¼¯ ---
if __name__ == "__main__":
    pdf_path = r"D:/æˆåŠŸå¤§å­¸/å­¸ç”Ÿè³‡æ–™/ç ”ç©¶åŠ©ç†/crossref API/submission/test.pdf"
    csv_output_path = "citations_output_v19_final.csv"
    
    print("æ­£åœ¨è®€å–ä¸¦è§£æ PDF...")
    full_text = pdf_to_text(pdf_path)
    m = REF_RE.search(full_text)
    body_text = full_text[: m.start()] if m else full_text
    
    print(">>> é–‹å§‹åŸ·è¡Œ V19 ç‰ˆã€Œç™½åå–®é€£æ¥è©ã€èˆ‡ã€Œä¸­è‹±åˆ†é›¢ã€ç­–ç•¥...")
    start_time = time.time()
    all_citations = extract_citations_v19(body_text)
    end_time = time.time()
    
    print(f"âœ… æ“·å–å®Œæˆï¼ç¸½å…±æ‰¾åˆ° {len(all_citations)} ç­†ç¨ç«‹å¼•ç”¨ï¼Œè€—æ™‚ {end_time - start_time:.4f} ç§’ã€‚")
    print("-" * 50)
    
    print("\n>>> ä»¥ä¸‹æ˜¯æ‰€æœ‰æ“·å–åˆ°çš„ç¨ç«‹å¼•ç”¨ (ä¾ä½œè€…æ’åº)ï¼š\n")
    pprint.pprint(all_citations)
    
    print("\n" + "-" * 50)
    print(f"\n>>> æ­£åœ¨å°‡å…¨éƒ¨ {len(all_citations)} ç­†çµæœåŒ¯å‡ºè‡³ {csv_output_path} ...")
    try:
        with open(csv_output_path, 'w', newline='', encoding='utf-8-sig') as csvfile:
            fieldnames = ['raw_text', 'author', 'year',]
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(all_citations)
        print(f"ğŸ‰ æˆåŠŸåŒ¯å‡º CSV æª”æ¡ˆï¼è«‹æŸ¥çœ‹ {csv_output_path}")
    except Exception as e:
        print(f"âŒ åŒ¯å‡º CSV æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")